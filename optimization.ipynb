{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (10,10)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "import re\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "import functools\n",
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "import librosa.display\n",
    "import hashlib\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from os import walk\n",
    "\n",
    "import glob\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Input, Masking, TimeDistributed, LSTM, Conv1D\n",
    "from keras.layers import GRU, Bidirectional, BatchNormalization, Reshape\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np_training = np.load('X_training.npy')\n",
    "Y_np_training = np.load('Y_training.npy') \n",
    "X_np_validation = np.load('X_validation.npy') \n",
    "Y_np_validation = np.load('Y_validation.npy')\n",
    "X_np_testing = np.load('X_testing.npy')\n",
    "Y_np_testing = np.load('Y_testing.npy')\n",
    "Y_oh_testing = np.load('Y_oh_testing.npy')\n",
    "Y_oh_validation = np.load('Y_oh_validation.npy')\n",
    "Y_oh_training = np.load('Y_oh_training.npy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
    "num_train_samples = X_np_training.shape[0]\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0812 11:06:30.636957 19916 deprecation.py:323] From C:\\Users\\karth\\Anaconda3\\lib\\site-packages\\tensorflow_model_optimization\\python\\core\\sparsity\\keras\\pruning_schedule.py:240: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "prune_low_magnitude_lstm_3 ( (None, 32)                19587     \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_activati (None, 32)                1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_3  (None, 6)                 392       \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_activati (None, 6)                 1         \n",
      "=================================================================\n",
      "Total params: 19,981\n",
      "Trainable params: 10,054\n",
      "Non-trainable params: 9,927\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model('my_model1.h5')\n",
    "\n",
    "epochs = 4\n",
    "end_step = np.ceil(1.0 * num_train_samples / batch_size).astype(np.int32) * epochs\n",
    "print(end_step)\n",
    "\n",
    "new_pruning_params = {\n",
    "      'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                   final_sparsity=0.90,\n",
    "                                                   begin_step=0,\n",
    "                                                   end_step=end_step,\n",
    "                                                   frequency=100)\n",
    "}\n",
    "\n",
    "new_pruned_model = sparsity.prune_low_magnitude(loaded_model, **new_pruning_params)\n",
    "new_pruned_model.summary()\n",
    "\n",
    "new_pruned_model.compile(\n",
    "    loss=tf.keras.losses.categorical_crossentropy,\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 84843 samples, validate on 9981 samples\n",
      "Epoch 1/4\n",
      "84843/84843 [==============================] - 55s 649us/sample - loss: 0.4727 - acc: 0.9056 - val_loss: 0.4569 - val_acc: 0.9073\n",
      "Epoch 2/4\n",
      "84843/84843 [==============================] - 54s 636us/sample - loss: 0.4595 - acc: 0.9056 - val_loss: 0.4558 - val_acc: 0.9073\n",
      "Epoch 3/4\n",
      "84843/84843 [==============================] - 54s 641us/sample - loss: 0.4561 - acc: 0.9056 - val_loss: 0.4526 - val_acc: 0.9073\n",
      "Epoch 4/4\n",
      "84843/84843 [==============================] - 54s 638us/sample - loss: 0.4527 - acc: 0.9056 - val_loss: 0.4501 - val_acc: 0.9073\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-1e3f624182e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m           validation_data=(X_np_validation, Y_oh_validation))\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_pruned_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test loss:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test accuracy:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    sparsity.UpdatePruningStep(),\n",
    "]\n",
    "\n",
    "new_pruned_model.fit(X_np_training, Y_oh_training,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=(X_np_validation, Y_oh_validation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 32)                9856      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 198       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 10,054\n",
      "Trainable params: 10,054\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model = sparsity.strip_pruning(new_pruned_model)\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.save('final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm_3_4/kernel:0 -- Total:5632, Zeros: 90.00%\n",
      "lstm_3_4/recurrent_kernel:0 -- Total:4096, Zeros: 89.99%\n",
      "lstm_3_4/bias:0 -- Total:128, Zeros: 0.00%\n",
      "dense_3_4/kernel:0 -- Total:192, Zeros: 90.10%\n",
      "dense_3_4/bias:0 -- Total:6, Zeros: 0.00%\n"
     ]
    }
   ],
   "source": [
    "for i, w in enumerate(final_model.get_weights()):\n",
    "    print(\n",
    "        \"{} -- Total:{}, Zeros: {:.2f}%\".format(\n",
    "            final_model.weights[i].name, w.size, np.sum(w == 0) / w.size * 100\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving pruned model to:  C:\\Users\\karth\\AppData\\Local\\Temp\\tmp3njvdgbt.h5\n",
      "Size of the pruned model before compression: 0.05 Mb\n",
      "Size of the pruned model after compression: 0.01 Mb\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import zipfile\n",
    "\n",
    "_, new_pruned_keras_file = tempfile.mkstemp(\".h5\")\n",
    "print(\"Saving pruned model to: \", new_pruned_keras_file)\n",
    "tf.keras.models.save_model(final_model, new_pruned_keras_file, include_optimizer=False)\n",
    "\n",
    "# Zip the .h5 model file\n",
    "_, zip3 = tempfile.mkstemp(\".zip\")\n",
    "with zipfile.ZipFile(zip3, \"w\", compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(new_pruned_keras_file)\n",
    "print(\n",
    "    \"Size of the pruned model before compression: %.2f Mb\"\n",
    "    % (os.path.getsize(new_pruned_keras_file) / float(2 ** 20))\n",
    ")\n",
    "print(\n",
    "    \"Size of the pruned model after compression: %.2f Mb\"\n",
    "    % (os.path.getsize(zip3) / float(2 ** 20))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
