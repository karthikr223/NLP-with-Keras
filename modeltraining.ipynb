{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (10,10)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "import re\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "import functools\n",
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "import librosa.display\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from os import walk\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = listdir('C:/Users/karth/Documents/Speech data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "validationlist = open('C:/Users/karth/Documents/Speech data txt/validation_list.txt')\n",
    "testinglist = open('C:/Users/karth/Documents/Speech data txt/testing_list.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_files = validationlist.read().splitlines()\n",
    "testing_files = testinglist.read().splitlines()\n",
    "X_validation = []\n",
    "Y_validation = []\n",
    "X_testing = []\n",
    "Y_testing = []\n",
    "X_training = []\n",
    "Y_training = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in validation_files:\n",
    "    data, sampling_rate = librosa.load('C:/Users/karth/Documents/Speech data/' + file) #replace with location of files\n",
    "    data = np.pad(data, (0,22050-len(data)), mode='constant', constant_values=0)\n",
    "    mfccs = librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=20)\n",
    "    X_validation.append(mfccs)\n",
    "    label = file.partition('/')[0]\n",
    "    Y_validation.append(label)\n",
    "for file in testing_files:\n",
    "    data, sampling_rate = librosa.load('C:/Users/karth/Documents/Speech data/' + file)\n",
    "    data = np.pad(data, (0,22050-len(data)), mode='constant', constant_values=0)\n",
    "    mfccs = librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=20) \n",
    "    X_testing.append(mfccs)\n",
    "    label = file.partition('/')[0]\n",
    "    Y_testing.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_training_files = validation_files + testing_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    dir = 'C:/Users/karth/Documents/Speech data/' + label\n",
    "    labelfiles = listdir(dir)\n",
    "    for i in labelfiles:\n",
    "        file = label + '/' + i\n",
    "        if file in non_training_files:\n",
    "            continue\n",
    "        else:\n",
    "            data, sampling_rate = librosa.load('C:/Users/karth/Documents/Speech data/' + file)\n",
    "            data = np.pad(data, (0,22050-len(data)), mode='constant', constant_values=0)\n",
    "            mfccs = librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=20) \n",
    "            X_training.append(mfccs)\n",
    "            Y_training.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np_training = np.array(X_training)\n",
    "Y_np_training = np.array(Y_training)\n",
    "X_np_validation = np.array(X_validation)\n",
    "Y_np_validation = np.array(Y_validation)\n",
    "X_np_testing = np.array(X_testing)\n",
    "Y_np_testing = np.array(Y_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('X_training.npy', X_np_training) - remove comment when running for the first time and creating the numpy sets\n",
    "#np.save('Y_training.npy', Y_np_training) \n",
    "#np.save('X_validation.npy', X_np_validation) \n",
    "#np.save('Y_validation.npy', Y_np_validation)\n",
    "#np.save('X_testing.npy', X_np_testing)\n",
    "#np.save('Y_testing.npy', Y_np_testing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Input, Masking, TimeDistributed, LSTM, Conv1D\n",
    "from keras.layers import GRU, Bidirectional, BatchNormalization, Reshape\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7504f986578d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlabelencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "temp1 = labelencoder.fit_transform(Y_np_training)\n",
    "Y2_training = [x if x < 5 else 5 for x in temp1]\n",
    "Y_oh_training = keras.utils.to_categorical(Y2_training) #using 5 of the trigger words to be recognized and the rest in one label category\n",
    "\n",
    "temp2 = labelencoder.fit_transform(Y_np_testing)\n",
    "Y2_testing = [x if x < 5 else 5 for x in temp2]\n",
    "Y_oh_testing = keras.utils.to_categorical(Y2_testing)\n",
    "\n",
    "temp3 = labelencoder.fit_transform(Y_np_validation)\n",
    "Y2_validation = [x if x < 5 else 5 for x in temp3]\n",
    "\n",
    "Y_oh_validation = keras.utils.to_categorical(Y2_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('Y_oh_testing.npy', Y_oh_testing)\n",
    "#np.save('Y_oh_validation.npy', Y_oh_validation)\n",
    "#np.save('Y_oh_training.npy', Y_oh_training) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np_training = np.load('X_training.npy')\n",
    "Y_np_training = np.load('Y_training.npy') \n",
    "X_np_validation = np.load('X_validation.npy') \n",
    "Y_np_validation = np.load('Y_validation.npy')\n",
    "X_np_testing = np.load('X_testing.npy')\n",
    "Y_np_testing = np.load('Y_testing.npy')\n",
    "Y_oh_testing = np.load('Y_oh_testing.npy')\n",
    "Y_oh_validation = np.load('Y_oh_validation.npy')\n",
    "Y_oh_training = np.load('Y_oh_training.npy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = Y_oh_training.shape[1]\n",
    "model2 = Sequential()\n",
    "model2.add(LSTM(32, input_shape = (20,44)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dense(num_labels))\n",
    "model2.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 32)                9856      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 198       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 10,054\n",
      "Trainable params: 10,054\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "print (model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 84843 samples, validate on 9981 samples\n",
      "Epoch 1/5\n",
      "84843/84843 [==============================] - 345s 4ms/step - loss: 0.4902 - acc: 0.9011 - val_loss: 0.4595 - val_acc: 0.9073\n",
      "Epoch 2/5\n",
      "84843/84843 [==============================] - 329s 4ms/step - loss: 0.4593 - acc: 0.9056 - val_loss: 0.4575 - val_acc: 0.9073\n",
      "Epoch 3/5\n",
      "84843/84843 [==============================] - 327s 4ms/step - loss: 0.4546 - acc: 0.9056 - val_loss: 0.4577 - val_acc: 0.9073\n",
      "Epoch 4/5\n",
      "84843/84843 [==============================] - 326s 4ms/step - loss: 0.4504 - acc: 0.9056 - val_loss: 0.4538 - val_acc: 0.9073\n",
      "Epoch 5/5\n",
      "84843/84843 [==============================] - 326s 4ms/step - loss: 0.4467 - acc: 0.9056 - val_loss: 0.4550 - val_acc: 0.9073\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d360eb1cc0>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit\n",
    "(X_np_training, Y_oh_training, batch_size=32, epochs=100, validation_data=(X_np_validation, Y_oh_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model.save('my_model1.h5')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
